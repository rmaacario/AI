from state import State
import sys


def applicable(state, actions):
    ''' Return a list of applicable actions in a given `state`. '''
    app = list()
    for act in actions:
        if State(state).intersect(act.precond) == act.precond:
            app.append(act)
    return app


def successorRelaxed(state, action):
    ''' Return the sucessor state generated by executing `action` in `state`. '''
    return State(action.pos_effect).union(state)


def h_naive(state=None, planning=None, goal=None):
    return 0


def h_add(state, planning, goal):
    '''
    Return heuristic h_add value for `state`.

    OBSERVATION: It receives `planning` object in order
    to access the applicable actions and problem information.
    '''
    #util.raiseNotDefined()
    ' YOUR CODE HERE '

    s_prepos = dict()
    actions = planning.actions
    a_state = state

    for prepos in a_state:
        s_prepos[prepos] = 0
    change = True

    while change:
        change = False
        actions_App = applicable(a_state, actions)
        for action in actions_App:
            aux_state = successorRelaxed(a_state, action)
            for effect in action.pos_effect:
                prev = s_prepos.get(effect,sys.maxsize)
                s_prepos[effect] = min(prev,(1+sum(s_prepos.get(pre, sys.maxsize) for pre in action.precond)))
                if prev != s_prepos[effect]:
                    change = True
    return sum(s_prepos.get(i,sys.maxsize) for i in goal)


def h_max(state, planning, goal=None):
    '''
    Return heuristic h_max value for `state`.

    OBSERVATION: It receives `planning` object in order
    to access the applicable actions and problem information.
    '''
    #util.raiseNotDefined()  (AQUI)
    ' YOUR CODE HERE '

    s_prepos = dict()
    actions = planning.actions
    a_state = state

    for prepos in a_state:
        s_prepos[prepos] = 0
    change = True

    while change:
        change = False
        actions_App = applicable(a_state, actions)
        for action in actions_App:
            a_state = successorRelaxed(a_state, action)
            for effect in action.pos_effect:
                prev = s_prepos.get(effect,sys.maxsize)
                s_prepos[effect] = min(prev,(1+sum(s_prepos.get(pre, sys.maxsize) for pre in action.precond)))
                if prev != s_prepos[effect]:
                    change = True
    h_max = 0

    for key in s_prepos:
        h_max = max(h_max, s_prepos.get(key))

    return h_max


def h_ff(state, planning, goal):
    '''
    Return heuristic h_ff value for `state`.

    OBSERVATION: It receives `planning` object in order
    to access the applicable actions and problem information.
    '''
    #util.raiseNotDefined()  (AQUI)
    ' YOUR CODE HERE '

    graph_plan = dict()
    actions = planning.actions
    a_state = state
    is_Goal = False

    if a_state.intersect(goal) == goal:
        return 0
    level = 0
    graph_plan[(level,'state')] = a_state

    while not is_Goal:
        actions_Applicable = applicable(a_state,actions)
        level += 1
        for a in actions_Applicable:
            a_state = successorRelaxed(a_state,a)
            if a_state.intersect(goal) == goal:
                is_Goal = True
                break
            graph_plan[(level,'state')] = a_state
            graph_plan[(level,'action')] = actions_Applicable

    thisLevels_Goals = set()
    thisLevels_Goals = thisLevels_Goals.union(goal)
    rlx_Actions = set()

    while (level > 0):
        previous_Levels_Goals = set()

        for tg in thisLevels_Goals:
            if tg in graph_plan[level-1,'state']:
                previous_Levels_Goals.add(tg)
            else:

                for a in graph_plan[level,'action']:
                    if tg in a.pos_effect:
                        previous_Levels_Goals = previous_Levels_Goals.union(a.precond)
                        rlx_Actions.add(a)
                        break

        level -= 1
        thisLevels_Goals = previous_Levels_Goals.copy()

    return len(rlx_Actions)
